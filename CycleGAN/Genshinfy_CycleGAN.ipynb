{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561},{"sourceId":737475,"sourceType":"datasetVersion","datasetId":379764}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CycleGAN: Human Faces to Anime Style\nModel 1 of **Genshinfy-UwU**. This model is used for style-transfer based pairing in creating a dataset for training a siamese network (Model 2 of **Genshinfy-UwU**) to compare similarity between human and anime faces.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport matplotlib.pyplot as plt # plotting\n\n\nimport tensorflow as tf\nimport keras\nfrom keras import layers, ops\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nautotune = tf.data.AUTOTUNE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:57:22.422172Z","iopub.execute_input":"2025-02-26T02:57:22.422461Z","iopub.status.idle":"2025-02-26T02:57:34.140836Z","shell.execute_reply.started":"2025-02-26T02:57:22.422420Z","shell.execute_reply":"2025-02-26T02:57:34.140215Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating a Custom Dataset","metadata":{}},{"cell_type":"code","source":"IMG_HEIGHT = 256\nIMG_WIDTH = 256\nBATCH_SIZE = 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:57:34.142097Z","iopub.execute_input":"2025-02-26T02:57:34.142657Z","iopub.status.idle":"2025-02-26T02:57:34.146050Z","shell.execute_reply.started":"2025-02-26T02:57:34.142625Z","shell.execute_reply":"2025-02-26T02:57:34.145308Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_image(path):\n    image = tf.io.read_file(path)\n    #if image.shape == ():\n    #    print(f\"Warning: Could not load image at {path}\")\n    #    return tf.zeros([IMG_HEIGHT, IMG_WIDTH, 3]) #return empty tensor\n    image = tf.image.decode_jpeg(image, channels=3) #remove RGBA from GenshinImpact\n    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n    image = (image / 127.5) - 1\n    return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:57:34.147460Z","iopub.execute_input":"2025-02-26T02:57:34.147763Z","iopub.status.idle":"2025-02-26T02:57:34.314820Z","shell.execute_reply.started":"2025-02-26T02:57:34.147732Z","shell.execute_reply":"2025-02-26T02:57:34.313828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_dataset(path):\n    image_paths = tf.data.Dataset.list_files(\n        os.path.join(path, '*'),\n        shuffle=True\n    )\n    dataset = image_paths.map(\n        load_image,\n        num_parallel_calls=autotune\n    )\n    dataset = dataset.batch(BATCH_SIZE).prefetch(autotune)\n    return dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:57:34.315695Z","iopub.execute_input":"2025-02-26T02:57:34.316013Z","iopub.status.idle":"2025-02-26T02:57:34.329376Z","shell.execute_reply.started":"2025-02-26T02:57:34.315980Z","shell.execute_reply":"2025-02-26T02:57:34.328612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"AnimeFaces = load_dataset('/kaggle/input/animefacedataset/images')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:57:34.330247Z","iopub.execute_input":"2025-02-26T02:57:34.330503Z","iopub.status.idle":"2025-02-26T02:58:14.668283Z","shell.execute_reply.started":"2025-02-26T02:57:34.330477Z","shell.execute_reply":"2025-02-26T02:58:14.667600Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CelebA = load_dataset('/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:58:14.670239Z","iopub.execute_input":"2025-02-26T02:58:14.670465Z","iopub.status.idle":"2025-02-26T02:59:38.254204Z","shell.execute_reply.started":"2025-02-26T02:58:14.670447Z","shell.execute_reply":"2025-02-26T02:59:38.253520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CycleDataset = tf.data.Dataset.zip((\n    CelebA.shuffle(buffer_size=256).take(1024),\n    AnimeFaces.shuffle(buffer_size=256).take(1024)\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:38.255660Z","iopub.execute_input":"2025-02-26T02:59:38.255874Z","iopub.status.idle":"2025-02-26T02:59:38.268984Z","shell.execute_reply.started":"2025-02-26T02:59:38.255855Z","shell.execute_reply":"2025-02-26T02:59:38.268327Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can visualize some of the images in our dataset.","metadata":{}},{"cell_type":"code","source":"_, ax = plt.subplots(2, 2, figsize=(12, 12))\nfor i, samples in enumerate(CycleDataset.take(2)):\n    real = (((samples[0][0] * 127.5) + 127.5).numpy()).astype(np.uint8)\n    fake = (((samples[1][0] * 127.5) + 127.5).numpy()).astype(np.uint8)\n    ax[i, 0].imshow(real)\n    ax[i, 1].imshow(fake)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:38.269644Z","iopub.execute_input":"2025-02-26T02:59:38.269859Z","iopub.status.idle":"2025-02-26T02:59:40.596054Z","shell.execute_reply.started":"2025-02-26T02:59:38.269840Z","shell.execute_reply":"2025-02-26T02:59:40.595152Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define Custom Layers","metadata":{}},{"cell_type":"code","source":"class ReflectionPadding2D(layers.Layer):\n    def __init__(self, padding=(1,1), **kwargs):\n        self.padding = tuple(padding)\n        super().__init__(**kwargs)\n\n    def call(self, inputs, mask=None):\n        pad_width, pad_height = self.padding\n        pad_tensor = [\n            [0, 0],\n            [pad_height, pad_height],\n            [pad_width, pad_width],\n            [0, 0]\n        ]\n        return ops.pad(inputs, pad_tensor, mode=\"REFLECT\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:40.596940Z","iopub.execute_input":"2025-02-26T02:59:40.597208Z","iopub.status.idle":"2025-02-26T02:59:40.601970Z","shell.execute_reply.started":"2025-02-26T02:59:40.597186Z","shell.execute_reply":"2025-02-26T02:59:40.601099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.initializers import RandomNormal\n\nKI = RandomNormal(mean=0.0, stddev=0.02)\nGI = RandomNormal(mean=0.0, stddev=0.02)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:40.602967Z","iopub.execute_input":"2025-02-26T02:59:40.603238Z","iopub.status.idle":"2025-02-26T02:59:40.616604Z","shell.execute_reply.started":"2025-02-26T02:59:40.603214Z","shell.execute_reply":"2025-02-26T02:59:40.615748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def ResidualBlock(\n    x,\n    activation,\n    kernel_initializer = KI,\n    kernel_size = (3, 3),\n    strides = (1, 1),\n    padding = \"valid\",\n    gamma_initializer = GI,\n    use_bias = False\n):\n    dim = x.shape[-1]\n    inputs = x\n    x = ReflectionPadding2D()(inputs)\n    x = layers.Conv2D(\n        dim,\n        kernel_size,\n        strides = strides,\n        kernel_initializer = kernel_initializer,\n        padding = padding,\n        use_bias = use_bias,\n    )(x)\n    x = layers.GroupNormalization(\n        groups = 1,\n        gamma_initializer = gamma_initializer,\n    )(x)\n    x = layers.add([inputs, x])\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:40.617436Z","iopub.execute_input":"2025-02-26T02:59:40.617739Z","iopub.status.idle":"2025-02-26T02:59:40.630383Z","shell.execute_reply.started":"2025-02-26T02:59:40.617713Z","shell.execute_reply":"2025-02-26T02:59:40.629684Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def DownSample(\n    x,\n    filters,\n    activation,\n    kernel_initializer = KI,\n    kernel_size = (3, 3),\n    strides = (2, 2),\n    padding = \"same\",\n    gamma_initializer = GI,\n    use_bias = False,\n):\n    x = layers.Conv2D(\n        filters,\n        kernel_size,\n        strides = strides,\n        kernel_initializer = kernel_initializer,\n        padding = padding,\n        use_bias = use_bias,\n    )(x)\n    x = layers.GroupNormalization(\n        groups = 1,\n        gamma_initializer = gamma_initializer,\n    )(x)\n    if activation: x = activation(x)\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:40.631018Z","iopub.execute_input":"2025-02-26T02:59:40.631238Z","iopub.status.idle":"2025-02-26T02:59:40.644406Z","shell.execute_reply.started":"2025-02-26T02:59:40.631220Z","shell.execute_reply":"2025-02-26T02:59:40.643762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def UpSample(\n    x,\n    filters,\n    activation,\n    kernel_initializer = KI,\n    kernel_size = (3, 3),\n    strides = (2, 2),\n    padding = \"same\",\n    gamma_initializer = GI,\n    use_bias = False,\n):\n    x = layers.Conv2DTranspose(\n        filters,\n        kernel_size,\n        strides = strides,\n        kernel_initializer = kernel_initializer,\n        padding = padding,\n        use_bias = use_bias,\n    )(x)\n    x = layers.GroupNormalization(\n        groups = 1,\n        gamma_initializer = gamma_initializer,\n    )(x)\n    if activation: x = activation(x)\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:40.645035Z","iopub.execute_input":"2025-02-26T02:59:40.645285Z","iopub.status.idle":"2025-02-26T02:59:40.663811Z","shell.execute_reply.started":"2025-02-26T02:59:40.645266Z","shell.execute_reply":"2025-02-26T02:59:40.663048Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Build a ResNet Model (CycleGAN Discriminator)","metadata":{}},{"cell_type":"code","source":"def ResNETGenerator(\n    filters = 64,\n    downsampling_blocks = 2,\n    residual_blocks = 9,\n    upsampling_blocks = 2,\n    gamma_initializer = GI,\n    name = \"ResNETGenerator\"\n):\n    image_input = layers.Input(shape=(256, 256, 3), name=name+\"_img_input\")\n    x = ReflectionPadding2D(padding=(3, 3))(image_input)\n    x = layers.Conv2D(\n        filters,\n        (7, 7),\n        kernel_initializer = KI,\n        use_bias = False,\n    )(x)\n    x = layers.GroupNormalization(\n        groups = 1,\n        gamma_initializer = gamma_initializer,\n    )(x)\n    x = layers.Activation(\"relu\")(x)\n\n    # Downsample\n    for _ in range(downsampling_blocks):\n        filters *= 2\n        x = DownSample(\n            x,\n            filters,\n            activation = layers.Activation(\"relu\")\n        )\n\n    # Residual Blocks\n    for _ in range(residual_blocks):\n        x = ResidualBlock(\n            x,\n            activation = layers.Activation(\"relu\")\n        )\n\n    # Upsample\n    for _ in range(upsampling_blocks):\n        filters //= 2\n        x = UpSample(\n            x,\n            filters,\n            activation = layers.Activation(\"relu\")\n        )\n\n    x = ReflectionPadding2D(padding=(3,3))(x)\n    x = layers.Conv2D(\n        3,\n        (7, 7),\n        padding = \"valid\",\n    )(x)\n    x = layers.Activation(\"tanh\")(x)\n\n    return keras.models.Model(image_input, x, name=name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:40.664561Z","iopub.execute_input":"2025-02-26T02:59:40.664869Z","iopub.status.idle":"2025-02-26T02:59:40.680289Z","shell.execute_reply.started":"2025-02-26T02:59:40.664842Z","shell.execute_reply":"2025-02-26T02:59:40.679517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TestResNET = ResNETGenerator()\nTestResNET.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:40.681042Z","iopub.execute_input":"2025-02-26T02:59:40.681255Z","iopub.status.idle":"2025-02-26T02:59:41.853900Z","shell.execute_reply.started":"2025-02-26T02:59:40.681237Z","shell.execute_reply":"2025-02-26T02:59:41.853253Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Build the CycleGAN Discriminator","metadata":{}},{"cell_type":"code","source":"def Discriminator(\n    filters = 64,\n    kernel_initializer = KI,\n    downsampling = 3,\n    name = \"Discriminator\",\n):\n    image_input = layers.Input(shape=(256,256,3), name=name+\"_img_input\")\n    x = layers.Conv2D(\n        filters,\n        (4, 4),\n        strides=(2, 2),\n        padding=\"same\",\n        kernel_initializer=kernel_initializer,\n    )(image_input)\n    x = layers.LeakyReLU(0.2)(x)\n\n    num_filters = filters\n    for block in range(downsampling):\n        num_filters *= 2\n        if block < 2:\n            x = DownSample(\n                x,\n                filters=num_filters,\n                activation=layers.LeakyReLU(0.2),\n                kernel_size=(4, 4),\n                strides=(2, 2),\n            )\n        else:\n            x = DownSample(\n                x,\n                filters=num_filters,\n                activation=layers.LeakyReLU(0.2),\n                kernel_size=(4, 4),\n                strides=(1, 1),\n            )\n\n    x = layers.Conv2D(\n        1,\n        (4, 4),\n        strides=(1, 1),\n        padding=\"same\",\n        kernel_initializer=kernel_initializer,\n    )(x)\n\n    return keras.models.Model(image_input, x, name=name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:41.854638Z","iopub.execute_input":"2025-02-26T02:59:41.854927Z","iopub.status.idle":"2025-02-26T02:59:41.860598Z","shell.execute_reply.started":"2025-02-26T02:59:41.854891Z","shell.execute_reply":"2025-02-26T02:59:41.859896Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TestDiscriminator = Discriminator()\nTestDiscriminator.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:41.861301Z","iopub.execute_input":"2025-02-26T02:59:41.861524Z","iopub.status.idle":"2025-02-26T02:59:41.942373Z","shell.execute_reply.started":"2025-02-26T02:59:41.861505Z","shell.execute_reply":"2025-02-26T02:59:41.941726Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Get the Generators and Discriminators","metadata":{}},{"cell_type":"code","source":"# Get the generators\ngen_G = ResNETGenerator(name=\"generator_G\")\ngen_F = ResNETGenerator(name=\"generator_F\")\n\n# Get the discriminators\ndisc_X = Discriminator(name=\"discriminator_X\")\ndisc_Y = Discriminator(name=\"discriminator_Y\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:41.945131Z","iopub.execute_input":"2025-02-26T02:59:41.945337Z","iopub.status.idle":"2025-02-26T02:59:42.439044Z","shell.execute_reply.started":"2025-02-26T02:59:41.945319Z","shell.execute_reply":"2025-02-26T02:59:42.438197Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Build the CycleGAN\n**Genshinfy-UwU Pipeline**    \nThe CycleGAN is to generate anime versions of human faces to serve as (human, anime) data pairs to the siamese network. This is because the siamese network is used for identifying the Genshin character most similar to the user's image. The style transfer model will then use these two images as input to Genshinfy the user.","metadata":{}},{"cell_type":"code","source":"tf.config.run_functions_eagerly(True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.440268Z","iopub.execute_input":"2025-02-26T02:59:42.440513Z","iopub.status.idle":"2025-02-26T02:59:42.444308Z","shell.execute_reply.started":"2025-02-26T02:59:42.440484Z","shell.execute_reply":"2025-02-26T02:59:42.443407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class GenshinfySiameseDataGenerator(keras.Model):\n    def __init__(\n        self,\n        generator_G,\n        generator_F,\n        discriminator_X,\n        discriminator_Y,\n        lambda_cycle = 10.0,\n        lambda_identity = 0.5,\n    ):\n        super().__init__()\n        self.gen_G = generator_G\n        self.gen_F = generator_F\n        self.disc_X = discriminator_X\n        self.disc_Y = discriminator_Y\n        self.lambda_cycle = lambda_cycle\n        self.lambda_identity = lambda_identity\n\n    def call(self, inputs):\n        return (\n            self.disc_X(inputs),\n            self.disc_Y(inputs),\n            self.gen_G(inputs),\n            self.gen_F(inputs),\n        )\n\n    def compile(\n        self,\n        gen_G_optimizer,\n        gen_F_optimizer,\n        disc_X_optimizer,\n        disc_Y_optimizer,\n        gen_loss_fn,\n        disc_loss_fn,\n    ):\n        super().compile()\n        self.gen_G_optimizer = gen_G_optimizer\n        self.gen_F_optimizer = gen_F_optimizer\n        self.disc_X_optimizer = disc_X_optimizer\n        self.disc_Y_optimizer = disc_Y_optimizer\n        self.generator_loss_fn = gen_loss_fn\n        self.discriminator_loss_fn = disc_loss_fn\n        self.cycle_loss_fn = keras.losses.MeanAbsoluteError()\n        self.identity_loss_fn = keras.losses.MeanAbsoluteError()\n\n    def train_step(self, inputs):\n        real_x, real_y = inputs # x is real, y is genshin\n        with tf.GradientTape(persistent=True) as tape:\n            fake_y = self.gen_G(real_x, training=True)\n            fake_x = self.gen_F(real_y, training=True)\n            cycled_x = self.gen_F(fake_y, training=True)\n            cycled_y = self.gen_G(fake_x, training=True)\n\n            # Identity mapping\n            same_x = self.gen_F(real_x, training=True)\n            same_y = self.gen_G(real_y, training=True)\n\n            # Discriminator output\n            disc_real_x = self.disc_X(real_x, training=True)\n            disc_fake_x = self.disc_X(fake_x, training=True)\n\n            disc_real_y = self.disc_Y(real_y, training=True)\n            disc_fake_y = self.disc_Y(fake_y, training=True)\n\n            # Generator adversarial loss\n            gen_G_loss = self.generator_loss_fn(disc_fake_y)\n            gen_F_loss = self.generator_loss_fn(disc_fake_x)\n\n            # Generator cycle loss\n            cycle_loss_G = self.cycle_loss_fn(real_y, cycled_y) * self.lambda_cycle\n            cycle_loss_F = self.cycle_loss_fn(real_x, cycled_x) * self.lambda_cycle\n\n            # Generator identity loss\n            id_loss_G = (\n                self.identity_loss_fn(real_y, same_y)\n                * self.lambda_cycle\n                * self.lambda_identity\n            )\n            id_loss_F = (\n                self.identity_loss_fn(real_x, same_x)\n                * self.lambda_cycle\n                * self.lambda_identity\n            )\n\n            # Total generator loss\n            total_loss_G = gen_G_loss + cycle_loss_G + id_loss_G\n            total_loss_F = gen_F_loss + cycle_loss_F + id_loss_F\n\n            # Discriminator loss\n            disc_X_loss = self.discriminator_loss_fn(disc_real_x, disc_fake_x)\n            disc_Y_loss = self.discriminator_loss_fn(disc_real_y, disc_fake_y)\n\n        # Get the gradients for the generators\n        grads_G = tape.gradient(total_loss_G, self.gen_G.trainable_variables)\n        grads_F = tape.gradient(total_loss_F, self.gen_F.trainable_variables)\n\n        # Get the gradients for the discriminators\n        disc_X_grads = tape.gradient(disc_X_loss, self.disc_X.trainable_variables)\n        disc_Y_grads = tape.gradient(disc_Y_loss, self.disc_Y.trainable_variables)\n\n        # Update the weights of the generators\n        self.gen_G_optimizer.apply_gradients(\n            zip(grads_G, self.gen_G.trainable_variables)\n        )\n        self.gen_F_optimizer.apply_gradients(\n            zip(grads_F, self.gen_F.trainable_variables)\n        )\n\n        # Update the weights of the discriminators\n        self.disc_X_optimizer.apply_gradients(\n            zip(disc_X_grads, self.disc_X.trainable_variables)\n        )\n        self.disc_Y_optimizer.apply_gradients(\n            zip(disc_Y_grads, self.disc_Y.trainable_variables)\n        )\n\n        return {\n            \"G_loss\": total_loss_G,\n            \"F_loss\": total_loss_F,\n            \"D_X_loss\": disc_X_loss,\n            \"D_Y_loss\": disc_Y_loss,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.445152Z","iopub.execute_input":"2025-02-26T02:59:42.445405Z","iopub.status.idle":"2025-02-26T02:59:42.462252Z","shell.execute_reply.started":"2025-02-26T02:59:42.445382Z","shell.execute_reply":"2025-02-26T02:59:42.461437Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Callback:**\nPeriodically saves generated images.","metadata":{}},{"cell_type":"code","source":"class GANMonitor(keras.callbacks.Callback):\n    def __init__(self, num_img=2, save_interval=5):  # New parameter for interval\n        self.num_img = num_img\n        self.save_interval = save_interval\n\n    def on_epoch_end(self, epoch, logs=None):\n        if (epoch + 1) % self.save_interval == 0:  # Only save every 20 epochs\n            _, ax = plt.subplots(2, self.num_img, figsize=(12, 12))\n            for i, img in enumerate(CelebA.shuffle(256).take(self.num_img)):\n                prediction = self.model.gen_G(img)[0].numpy()\n                prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n                img = (img[0] * 127.5 + 127.5).numpy().astype(np.uint8)\n\n                ax[0, i].imshow(img)\n                ax[1, i].imshow(prediction)\n                ax[0, i].set_title(\"Input Image\")\n                ax[1, i].set_title(\"Translated Image\")\n                ax[0, i].axis(\"off\")\n                ax[1, i].axis(\"off\")\n\n                prediction = keras.utils.array_to_img(prediction)\n                prediction.save(\n                    \"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch + 1)\n                )\n            plt.show()\n            plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.462988Z","iopub.execute_input":"2025-02-26T02:59:42.463273Z","iopub.status.idle":"2025-02-26T02:59:42.482905Z","shell.execute_reply.started":"2025-02-26T02:59:42.463245Z","shell.execute_reply":"2025-02-26T02:59:42.482202Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train the Model","metadata":{}},{"cell_type":"code","source":"adv_loss_fn = keras.losses.MeanSquaredError()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.483777Z","iopub.execute_input":"2025-02-26T02:59:42.484033Z","iopub.status.idle":"2025-02-26T02:59:42.500121Z","shell.execute_reply.started":"2025-02-26T02:59:42.484002Z","shell.execute_reply":"2025-02-26T02:59:42.499396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generator_loss_fn(fake):\n    fake_loss = adv_loss_fn(ops.ones_like(fake), fake)\n    return fake_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.500952Z","iopub.execute_input":"2025-02-26T02:59:42.501232Z","iopub.status.idle":"2025-02-26T02:59:42.515098Z","shell.execute_reply.started":"2025-02-26T02:59:42.501207Z","shell.execute_reply":"2025-02-26T02:59:42.514209Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def discriminator_loss_fn(real, fake):\n    real_loss = adv_loss_fn(ops.ones_like(real), real)\n    fake_loss = adv_loss_fn(ops.zeros_like(fake), fake)\n    return (real_loss + fake_loss) * 0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.515916Z","iopub.execute_input":"2025-02-26T02:59:42.516204Z","iopub.status.idle":"2025-02-26T02:59:42.536054Z","shell.execute_reply.started":"2025-02-26T02:59:42.516184Z","shell.execute_reply":"2025-02-26T02:59:42.535305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = GenshinfySiameseDataGenerator(\n    generator_G=gen_G,\n    generator_F=gen_F,\n    discriminator_X=disc_X,\n    discriminator_Y=disc_Y\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.536902Z","iopub.execute_input":"2025-02-26T02:59:42.537186Z","iopub.status.idle":"2025-02-26T02:59:42.550630Z","shell.execute_reply.started":"2025-02-26T02:59:42.537161Z","shell.execute_reply":"2025-02-26T02:59:42.549893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(\n    gen_G_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    gen_F_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    disc_X_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    disc_Y_optimizer=keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5),\n    gen_loss_fn=generator_loss_fn,\n    disc_loss_fn=discriminator_loss_fn,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.551453Z","iopub.execute_input":"2025-02-26T02:59:42.551693Z","iopub.status.idle":"2025-02-26T02:59:42.584159Z","shell.execute_reply.started":"2025-02-26T02:59:42.551671Z","shell.execute_reply":"2025-02-26T02:59:42.583423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plotter = GANMonitor()\ncheckpoint_filepath = \"./model_checkpoints/cyclegan_checkpoints.weights.h5\"\nmodel_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath, save_weights_only=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.585046Z","iopub.execute_input":"2025-02-26T02:59:42.585299Z","iopub.status.idle":"2025-02-26T02:59:42.588852Z","shell.execute_reply.started":"2025-02-26T02:59:42.585281Z","shell.execute_reply":"2025-02-26T02:59:42.588062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.fit(\n    CycleDataset.take(256),\n    epochs=10,\n    callbacks=[plotter, model_checkpoint_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T02:59:42.589663Z","iopub.execute_input":"2025-02-26T02:59:42.589934Z","iopub.status.idle":"2025-02-26T04:13:17.336223Z","shell.execute_reply.started":"2025-02-26T02:59:42.589913Z","shell.execute_reply":"2025-02-26T04:13:17.335038Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
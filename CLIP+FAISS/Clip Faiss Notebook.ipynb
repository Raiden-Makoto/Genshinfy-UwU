{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10974392,
          "sourceType": "datasetVersion",
          "datasetId": 6728735
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-09T23:17:47.244639Z",
          "iopub.execute_input": "2025-03-09T23:17:47.244943Z",
          "iopub.status.idle": "2025-03-09T23:17:47.249583Z",
          "shell.execute_reply.started": "2025-03-09T23:17:47.244918Z",
          "shell.execute_reply": "2025-03-09T23:17:47.247942Z"
        },
        "id": "u80WkG9vt_nY"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install faiss-cpu"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-09T23:17:48.822628Z",
          "iopub.execute_input": "2025-03-09T23:17:48.823061Z",
          "iopub.status.idle": "2025-03-09T23:17:52.255441Z",
          "shell.execute_reply.started": "2025-03-09T23:17:48.823027Z",
          "shell.execute_reply": "2025-03-09T23:17:52.253844Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA_2fhzmt_nY",
        "outputId": "e0e3a44a-aff0-40c4-d306-4da50cd0ba55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install datasets"
      ],
      "metadata": {
        "id": "-NzBViMDuMkY",
        "outputId": "8099059c-af9d-4eaa-fc2f-fb4431bb9e84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/485.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m481.3/485.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Raiden-Makoto/Genshinfy-UwU"
      ],
      "metadata": {
        "id": "awvaRq1duQBE",
        "outputId": "e459d075-15a6-4d03-8822-4f6ac38207b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Genshinfy-UwU'...\n",
            "remote: Enumerating objects: 168, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (159/159), done.\u001b[K\n",
            "remote: Total 168 (delta 31), reused 125 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (168/168), 37.09 MiB | 18.29 MiB/s, done.\n",
            "Resolving deltas: 100% (31/31), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Genshinfy-UwU"
      ],
      "metadata": {
        "id": "-7hx64HiuVbo",
        "outputId": "65aa2ddd-2808-41e6-b2f9-95828807c717",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Genshinfy-UwU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset\n",
        "from datasets import Image as IMG\n",
        "from typing import List, Union, Tuple\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "import faiss\n",
        "import glob"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-09T23:17:52.257023Z",
          "iopub.execute_input": "2025-03-09T23:17:52.257315Z",
          "iopub.status.idle": "2025-03-09T23:17:52.262579Z",
          "shell.execute_reply.started": "2025-03-09T23:17:52.257261Z",
          "shell.execute_reply": "2025-03-09T23:17:52.261078Z"
        },
        "id": "mft0Des0t_nZ"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = './GenshinCharacters'\n",
        "img_files = glob.glob(img_path + \"/*.[jJpP][pPnN][gG]\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-09T23:17:54.679037Z",
          "iopub.execute_input": "2025-03-09T23:17:54.679400Z",
          "iopub.status.idle": "2025-03-09T23:17:54.691775Z",
          "shell.execute_reply.started": "2025-03-09T23:17:54.679371Z",
          "shell.execute_reply": "2025-03-09T23:17:54.690689Z"
        },
        "id": "-XMxjwPPt_nZ"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "img_files = sorted(img_files)\n",
        "img_files[0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-09T23:18:00.688479Z",
          "iopub.execute_input": "2025-03-09T23:18:00.688873Z",
          "iopub.status.idle": "2025-03-09T23:18:00.695468Z",
          "shell.execute_reply.started": "2025-03-09T23:18:00.688841Z",
          "shell.execute_reply": "2025-03-09T23:18:00.693804Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NPhI7gWdt_nZ",
        "outputId": "4df73a70-c146-4352-c59c-e070f9d0f1ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./GenshinCharacters/Albedo.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-09T23:18:02.894205Z",
          "iopub.execute_input": "2025-03-09T23:18:02.894518Z",
          "iopub.status.idle": "2025-03-09T23:18:04.270842Z",
          "shell.execute_reply.started": "2025-03-09T23:18:02.894500Z",
          "shell.execute_reply": "2025-03-09T23:18:04.269767Z"
        },
        "id": "InruEK-ot_nZ"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_images(\n",
        "    images: Union[List[str], List[PIL.Image.Image]],\n",
        "    batch_size: int\n",
        "):\n",
        "    def transform_func(x):\n",
        "        if isinstance(x['image'], PIL.Image.Image):\n",
        "            image = x['image']\n",
        "        else:\n",
        "            image = [IMG().decode_example(img) for img in x['image']]\n",
        "        return processor(images=image, return_tensors='pt')\n",
        "\n",
        "    dataset = Dataset.from_dict({'image' : images})\n",
        "    dataset = dataset.cast_column('image', IMG(decode=False)) \\\n",
        "                if isinstance(images[0], str) \\\n",
        "                else dataset\n",
        "    dataset.set_format('torch')\n",
        "    dataset.set_transform(transform_func)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    image_embeddings = []\n",
        "    progress = tqdm(total=len(images)//batch_size, position=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k : v.to(device) for k,v in batch.items()}\n",
        "            image_embeddings.extend(\n",
        "                model.get_image_features(**batch).detach().cpu().numpy()\n",
        "            )\n",
        "            progress.update(1)\n",
        "        progress.close()\n",
        "    return np.stack(image_embeddings)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-09T23:18:05.152218Z",
          "iopub.execute_input": "2025-03-09T23:18:05.152830Z",
          "iopub.status.idle": "2025-03-09T23:18:05.161200Z",
          "shell.execute_reply.started": "2025-03-09T23:18:05.152784Z",
          "shell.execute_reply": "2025-03-09T23:18:05.160159Z"
        },
        "id": "uz0yNHmlt_nZ"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "vector_embedding = np.array(encode_images(img_files, 7))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-09T23:18:06.933376Z",
          "iopub.execute_input": "2025-03-09T23:18:06.933676Z",
          "iopub.status.idle": "2025-03-09T23:18:16.236472Z",
          "shell.execute_reply.started": "2025-03-09T23:18:06.933653Z",
          "shell.execute_reply": "2025-03-09T23:18:16.235593Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azy5KeNLt_nZ",
        "outputId": "9e4dbf3a-3419-4902-be32-e31501aa29cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "14it [00:20,  1.46s/it]\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "# Store Embeddings\n",
        "with open('vector_embedding.pkl', 'wb') as f:\n",
        "    pickle.dump(vector_embedding, f)"
      ],
      "metadata": {
        "id": "MOWlkVA6xWuB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = faiss.IndexFlatIP(vector_embedding.shape[1]) #inner product similarity\n",
        "indexer.add(vector_embedding)"
      ],
      "metadata": {
        "id": "XxVcSCkGxgf4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_text(\n",
        "    text: List[str],\n",
        "    batch_size: int\n",
        "):\n",
        "    dev = \"cpu\"\n",
        "    dataset = Dataset.from_dict({'text' : text})\n",
        "    dataset = dataset.map(\n",
        "        lambda x: processor(\n",
        "            text = x['text'],\n",
        "            padding = True,\n",
        "            return_tensors = 'pt',\n",
        "            max_length = 77,\n",
        "            truncation = True,\n",
        "        ),\n",
        "        batched=True,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    dataset.set_format('torch')\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    text_embeddings = []\n",
        "    progress = tqdm(total=len(text)//batch_size, position=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = {k : v.to(dev) for k,v in batch.items()}\n",
        "            text_embeddings.extend(\n",
        "                model.get_text_features(**batch).detach().cpu().numpy()\n",
        "            )\n",
        "            progress.update(1)\n",
        "        progress.close()\n",
        "    return np.stack(text_embeddings)\n"
      ],
      "metadata": {
        "id": "q96KqSAT0jwR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTPoALOb2XyC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10974392,"sourceType":"datasetVersion","datasetId":6728735}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport PIL\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport pickle\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:17:47.244639Z","iopub.execute_input":"2025-03-09T23:17:47.244943Z","iopub.status.idle":"2025-03-09T23:17:47.249583Z","shell.execute_reply.started":"2025-03-09T23:17:47.244918Z","shell.execute_reply":"2025-03-09T23:17:47.247942Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"!pip -q install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:17:48.822628Z","iopub.execute_input":"2025-03-09T23:17:48.823061Z","iopub.status.idle":"2025-03-09T23:17:52.255441Z","shell.execute_reply.started":"2025-03-09T23:17:48.823027Z","shell.execute_reply":"2025-03-09T23:17:52.253844Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom datasets import Dataset\nfrom datasets import Image as IMG\nfrom typing import List, Union, Tuple\nfrom transformers import CLIPProcessor, CLIPModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:17:52.257023Z","iopub.execute_input":"2025-03-09T23:17:52.257315Z","iopub.status.idle":"2025-03-09T23:17:52.262579Z","shell.execute_reply.started":"2025-03-09T23:17:52.257261Z","shell.execute_reply":"2025-03-09T23:17:52.261078Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"import faiss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:17:52.264711Z","iopub.execute_input":"2025-03-09T23:17:52.265080Z","iopub.status.idle":"2025-03-09T23:17:52.284433Z","shell.execute_reply.started":"2025-03-09T23:17:52.265050Z","shell.execute_reply":"2025-03-09T23:17:52.283156Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"import glob\n\nimg_path = '/kaggle/input/genhincharacters'\nimg_files = glob.glob(img_path + \"/*.[jJpP][pPnN][gG]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:17:54.679037Z","iopub.execute_input":"2025-03-09T23:17:54.679400Z","iopub.status.idle":"2025-03-09T23:17:54.691775Z","shell.execute_reply.started":"2025-03-09T23:17:54.679371Z","shell.execute_reply":"2025-03-09T23:17:54.690689Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"img_files = sorted(img_files)\nimg_files[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:18:00.688479Z","iopub.execute_input":"2025-03-09T23:18:00.688873Z","iopub.status.idle":"2025-03-09T23:18:00.695468Z","shell.execute_reply.started":"2025-03-09T23:18:00.688841Z","shell.execute_reply":"2025-03-09T23:18:00.693804Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'/kaggle/input/genhincharacters/Albedo.png'"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"device = \"cpu\"\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:18:02.894205Z","iopub.execute_input":"2025-03-09T23:18:02.894518Z","iopub.status.idle":"2025-03-09T23:18:04.270842Z","shell.execute_reply.started":"2025-03-09T23:18:02.894500Z","shell.execute_reply":"2025-03-09T23:18:04.269767Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"def encode_images(\n    images: Union[List[str], List[PIL.Image.Image]],\n    batch_size: int\n):\n    def transform_func(x):\n        if isinstance(x['image'], PIL.Image.Image):\n            image = x['image']\n        else:\n            image = [IMG().decode_example(img) for img in x['image']]\n        return processor(images=image, return_tensors='pt')\n\n    dataset = Dataset.from_dict({'image' : images})\n    dataset = dataset.cast_column('image', IMG(decode=False)) \\\n                if isinstance(images[0], str) \\\n                else dataset\n    dataset.set_format('torch')\n    dataset.set_transform(transform_func)\n    dataloader = DataLoader(dataset, batch_size=batch_size)\n    image_embeddings = []\n    progress = tqdm(total=len(images)//batch_size, position=0)\n    \n    with torch.no_grad():\n        for batch in dataloader:\n            batch = {k : v.to(device) for k,v in batch.items()}\n            image_embeddings.extend(\n                model.get_image_features(**batch).detach().cpu().numpy()\n            )\n            progress.update(1)\n        progress.close()\n    return np.stack(image_embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:18:05.152218Z","iopub.execute_input":"2025-03-09T23:18:05.152830Z","iopub.status.idle":"2025-03-09T23:18:05.161200Z","shell.execute_reply.started":"2025-03-09T23:18:05.152784Z","shell.execute_reply":"2025-03-09T23:18:05.160159Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"vector_embedding = np.array(encode_images(img_files, 7))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T23:18:06.933376Z","iopub.execute_input":"2025-03-09T23:18:06.933676Z","iopub.status.idle":"2025-03-09T23:18:16.236472Z","shell.execute_reply.started":"2025-03-09T23:18:06.933653Z","shell.execute_reply":"2025-03-09T23:18:16.235593Z"}},"outputs":[{"name":"stderr","text":"14it [00:09,  1.51it/s]                        \n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}